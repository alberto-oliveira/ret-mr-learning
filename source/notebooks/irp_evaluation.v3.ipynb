{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "The raw code for this IPython notebook is by default hidden for easier reading.\n",
       "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_notebook():\n",
    "    return display(Javascript(\"IPython.notebook.save_notebook()\"),\n",
    "                   include=['application/javascript'])\n",
    "\n",
    "def output_HTML(read_file, output_file):\n",
    "    from nbconvert import HTMLExporter\n",
    "    import codecs\n",
    "    import nbformat\n",
    "    exporter = HTMLExporter()\n",
    "    # read_file is '.ipynb', output_file is '.html'\n",
    "    output_notebook = nbformat.read(read_file, as_version=4)\n",
    "    output, resources = exporter.from_notebook_node(output_notebook)\n",
    "    codecs.open(output_file, 'w', encoding='utf-8').write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import warnings\n",
    "sys.path.append('../')\n",
    "\n",
    "from rankutils.mappings import ranking_type_map\n",
    "from rankutils.cfgloader import cfgloader\n",
    "from rankutils.evaluation import Evaluator\n",
    "from rankutils.drawing import colors_from_cmap, irp_results_barh_draw, irp_results_pos_draw, rpp_results_draw\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mpld3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathcfg = cfgloader(\"/home/alberto/phD/projects/performance_prediction/ret-mr-learning/source/path_2.cfg\")\n",
    "evalcfgfile = \"/home/alberto/phD/projects/performance_prediction/ret-mr-learning/source/evalcfg/0002.test_eval.cfg\"\n",
    "barfigsize=(20, 8)\n",
    "linefigsize=(15, 15)\n",
    "titleargs=dict(fontsize=10, horizontalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating :   0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-70f8087a85f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Evaluating '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mevaluators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalcfgfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevalcfgfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpathcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mevaluators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/phD/projects/performance_prediction/ret-mr-learning/source/rankutils/evaluation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, evalcfgfile, key, pathcfg)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlblpath\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutpath\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrespath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_results_data_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/phD/projects/performance_prediction/ret-mr-learning/source/rankutils/evaluation.py\u001b[0m in \u001b[0;36mload_results_data_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mirp_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{0:s}/*irp.npy\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mmdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'irp_results'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mirp_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mmdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'irp_results'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Empty IRP Predicted Labels at: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{0:s}/\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "evaluators = dict()\n",
    "\n",
    "#keys = ['oxford_001', 'unicamp_001', 'places365_001', 'places365_002', 'places365_003',\n",
    "#        'vggfaces_001', 'vggfaces_002', 'vggfaces_003', 'imagenet_001', 'imagenet_004',\n",
    "#        'imagenet_003']\n",
    "\n",
    "#keys = ['vggfaces_001', 'vggfaces_002', 'vggfaces_003', 'vggfaces_004', 'vggfaces_005',\n",
    "#        'places365_001', 'places365_002', 'places365_003', 'places365_004', 'places365_005',\n",
    "#        'imagenet_001', 'imagenet_004', 'imagenet_003', 'imagenet_002']\n",
    "\n",
    "#keys = ['multimodal_003', 'multimodal_004',\n",
    "#        'multimodal_006', 'multimodal_010',\n",
    "#        'multimodal_012']#\n",
    "\n",
    "keys = ['places365_001', 'places365_002', 'places365_003', 'places365_004', 'places365_005',\n",
    "        'vggfaces_001', 'vggfaces_002', 'vggfaces_003', 'vggfaces_004', 'vggfaces_005']\n",
    "\n",
    "aliases = dict(oxford_001='OXF SURF-2000 Votes', unicamp_001='UNI SURF-2000 Votes',\n",
    "               places365_001='P365 VGG16-L2Sq', places365_002='P365 R152-L2Sq',\n",
    "               places365_003='P365 VGG16-Cos', places365_004='P365 VGG16-Cheby',\n",
    "               places365_005='P365 VGG16-Canb', vggfaces_001='VGGF VGG16-L2Sq',\n",
    "               vggfaces_002='VGGF VGG16-L2Sq + Pert', vggfaces_003='VGGF VGG16-Cos',\n",
    "               vggfaces_004='VGGF VGG16-Cheb', vggfaces_005='VGGF VGG16-Canb',\n",
    "               imagenet_001='INET Rv2-L2Sq', imagenet_004='INET Rv2-Canb',\n",
    "               imagenet_003='INET Rv2-Cheb', imagenet_002='INET Rv2-Cos',\n",
    "               MPEG7_001='MPEG-7 BAS', MPEG7_002=\"MPEG-7 IDSC\",\n",
    "               MPEG7_003=\"MPEG-7 ASC\", MPEG7_004=\"MPEG-7 AIR\",\n",
    "               MPEG7_005=\"MPEG-7 CFD\", multimodal_003=\"Text FV DICE\",\n",
    "               multimodal_004=\"Text FV BoW\", multimodal_006=\"Text FV Jaccard\",\n",
    "               multimodal_010=\"Img. FV CSD\", multimodal_012=\"Img. FV Color Bmap\")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for i in tqdm(range(len(keys)), desc='Evaluating ', total=len(keys)):\n",
    "        k = keys[i]\n",
    "        evaluators[k] = Evaluator(evalcfgfile=evalcfgfile, key=k, pathcfg=pathcfg)\n",
    "        evaluators[k].evaluate_v2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional nACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 1, sharey=True, sharex=True)\n",
    "axes = axes.reshape(-1)\n",
    "fig.set_size_inches((10, 30))\n",
    "\n",
    "\n",
    "for i, key in enumerate(keys):\n",
    "    axes[i].set_title(\"{0:s}\".format(aliases[key]), fontdict=titleargs)\n",
    "    \n",
    "    \n",
    "    if i%2 == 0:\n",
    "        ylb = 'nACC'\n",
    "    else:\n",
    "        ylb = None\n",
    "        \n",
    "    if i == 9 or i == 10:\n",
    "        xlb = 'Rank Position'\n",
    "    else:\n",
    "        xlb = None\n",
    "    \n",
    "    try:\n",
    "        h, l = irp_results_pos_draw(evaluators[key].data, evaluators[key].k, ax=axes[i], measure='NACC', xlabel=xlb, ylabel=ylb)\n",
    "        hand = h\n",
    "        lab = l\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    if i == len(keys)-1:\n",
    "        fig.legend(hand, lab, fancybox=True, shadow=True, loc='upper center', bbox_to_anchor=[0.5, 1.0], ncol=2,\n",
    "                  fontsize='large')\n",
    "            \n",
    "\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.92)\n",
    "#plt.savefig('/home/alberto/Dropbox/ICASSP-2019_ML_Relevance_Prediction/tex/figures/ICASSP_2019_Pos-NACC.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional F1-Score - OFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(6, 2, sharey=True, sharex=True)\n",
    "# axes = axes.reshape(-1)\n",
    "# fig.set_size_inches((12, 24))\n",
    "\n",
    "# for i, key in enumerate(keys):\n",
    "#     axes[i].set_title(\"{0:s}\".format(aliases[key]), fontdict=titleargs)\n",
    "    \n",
    "    \n",
    "#     if i%2 == 0:\n",
    "#         ylb = 'nACC'\n",
    "#     else:\n",
    "#         ylb = None\n",
    "        \n",
    "#     if i == 9 or i == 10:\n",
    "#         xlb = 'Rank Position'\n",
    "#     else:\n",
    "#         xlb = None\n",
    "    \n",
    "#     try:\n",
    "#         h, l = irp_results_pos_draw(evaluators[key].data, 10, ax=axes[i], measure='F-Score', xlabel=xlb, ylabel=ylb)\n",
    "#         hand = h\n",
    "#         lab = l\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "    \n",
    "#     if i == len(keys)-1:\n",
    "#         fig.legend(hand, lab, fancybox=True, shadow=True, loc='upper center', bbox_to_anchor=[0.5, 1.0], ncol=2,\n",
    "#                   fontsize='large')\n",
    "\n",
    "# fig.tight_layout()\n",
    "# plt.subplots_adjust(top=0.92)\n",
    "# #plt.savefig('/home/alberto/Dropbox/ICASSP-2019_ML_Relevance_Prediction/tex/figures/ICASSP_2019_Pos-Fscore.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, sharey=True, sharex=True)\n",
    "axes = axes.reshape(-1)\n",
    "fig.set_size_inches((12, 12))\n",
    "\n",
    "\n",
    "for i, key in enumerate(keys):\n",
    "    axes[i].set_title(\"{0:s}\".format(aliases[key]), fontdict=titleargs)\n",
    "        \n",
    "    if i == 9 or i == 10:\n",
    "        xlb = 'MCC'\n",
    "    else:\n",
    "        xlb = None\n",
    "    \n",
    "    irp_results_barh_draw(evaluators[key].data, 'MCC', ax=axes[i], xlabel=xlb)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
